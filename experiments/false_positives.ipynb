{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### RWSE-Checker: false-positives (false alarm) statistics from filtered corpus",
   "id": "421a2e9efb7631ae"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T12:08:57.124788Z",
     "start_time": "2025-01-21T12:08:55.897551Z"
    }
   },
   "source": "from rwse import RWSE_Checker",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgardner/GitHub/catalpa-cl/rwse-experiments/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:08:58.218879Z",
     "start_time": "2025-01-21T12:08:57.128790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rwse = RWSE_Checker()\n",
    "rwse.set_confusion_sets('../data/confusion_sets_modified.csv')"
   ],
   "id": "a0932c10ebc1e5af",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/dgardner/GitHub/catalpa-cl/rwse-experiments/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Read from corpus and collect sentences by confusion sets",
   "id": "b15b220fc4c36fa6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:09:29.125822Z",
     "start_time": "2025-01-21T12:08:58.317387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../data/eng_news_2023_10K-sentences.txt', 'r') as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "sentences_cleaned = [sentence.split('\\t')[1].strip() for sentence in sentences]\n",
    "\n",
    "from util import collect_sentences_by_confusion_sets\n",
    "\n",
    "sentences_by_confusion_sets = collect_sentences_by_confusion_sets(rwse.confusion_sets.values(), sentences_cleaned)\n",
    "\n",
    "total = 0\n",
    "\n",
    "for key, value in sentences_by_confusion_sets.items():\n",
    "    total += len(value)\n",
    "    print(key, '=', len(value))\n",
    "\n",
    "print('total =', total)"
   ],
   "id": "ad7219e32c9680b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accept,except = 20\n",
      "advise,advice = 21\n",
      "affect,effect = 31\n",
      "begin,being = 213\n",
      "bitch,pitch = 7\n",
      "brakes,breaks = 7\n",
      "burrows,borrows = 0\n",
      "sight,site = 29\n",
      "cords,chords = 0\n",
      "country,county = 100\n",
      "crap,crab = 2\n",
      "dessert,desert = 6\n",
      "ease,easy = 30\n",
      "effects,affects = 23\n",
      "extend,extent = 16\n",
      "feet,feat = 21\n",
      "few,view = 103\n",
      "form,from = 839\n",
      "forth,fourth = 33\n",
      "forums,forms = 3\n",
      "fund,found = 115\n",
      "lead,led = 96\n",
      "life,live = 147\n",
      "loose,lose = 20\n",
      "mad,made = 154\n",
      "or,ore = 413\n",
      "passed,past = 80\n",
      "peace,piece = 28\n",
      "plane,plain = 12\n",
      "principal,principle = 13\n",
      "quite,quiet = 37\n",
      "raise,rise = 32\n",
      "safe,save = 48\n",
      "spit,split = 9\n",
      "than,then = 419\n",
      "their,there,they = 1421\n",
      "theme,them = 246\n",
      "things,thinks = 69\n",
      "trail,trial = 27\n",
      "tree,three = 174\n",
      "two,too,to = 4563\n",
      "weak,week = 121\n",
      "weather,whether = 56\n",
      "weed,wheat = 1\n",
      "where,were = 598\n",
      "which,witch = 424\n",
      "whole,hole = 33\n",
      "with,width = 1383\n",
      "world,word = 119\n",
      "you,your = 698\n",
      "total = 13060\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Determine RWSEs",
   "id": "f1becca5e6105f9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:15:12.510924Z",
     "start_time": "2025-01-21T12:15:12.243727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cassis import Cas, load_typesystem\n",
    "import spacy\n",
    "\n",
    "T_SENTENCE = 'de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Sentence'\n",
    "T_RWSE = 'de.tudarmstadt.ukp.dkpro.core.api.anomaly.type.RWSE'\n",
    "T_TOKEN = 'de.tudarmstadt.ukp.dkpro.core.api.segmentation.type.Token'\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "path = '../data/TypeSystem.xml'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    ts = load_typesystem(f)\n",
    "\n",
    "S = ts.get_type(T_SENTENCE)\n",
    "T = ts.get_type(T_TOKEN)\n",
    "\n",
    "result = dict()"
   ],
   "id": "757c9a6da4c9b8b6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:27:59.747306Z",
     "start_time": "2025-01-21T12:16:03.836779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for confusion_set, sentences in sentences_by_confusion_sets.items():\n",
    "    matches = 0\n",
    "    rwse.set_confusion_sets([set(confusion_set.split(','))])\n",
    "    for sentence in sentences:\n",
    "        cas = Cas(ts)\n",
    "        # TODO clean sentence?\n",
    "        cas.sofa_string = sentence\n",
    "        doc = nlp(cas.sofa_string)\n",
    "        cas_sentence = S(begin=0, end=len(sentence))\n",
    "        cas.add(cas_sentence)\n",
    "        for token in doc:\n",
    "            cas_token = T(begin=token.idx, end=token.idx+len(token.text), id=token.i)\n",
    "            cas.add(cas_token)\n",
    "        rwse.check_cas(cas, ts)\n",
    "        false_positives = cas.select(T_RWSE)\n",
    "        if len(false_positives) != 0:\n",
    "            matches += 1\n",
    "            with open('../experiments/data/false_positives.csv', 'a') as f:\n",
    "                print(confusion_set, cas.sofa_string, sep='\\t', file=f)\n",
    "    result[confusion_set] = {\n",
    "        'num_sentences':len(sentences),\n",
    "        'num_matches':matches,\n",
    "    }"
   ],
   "id": "2db82ca79085232b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Determine false-positive rate",
   "id": "93f59c11ebde61c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:46:15.998763Z",
     "start_time": "2025-01-21T12:46:15.994355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total = sum(item['num_sentences'] for item in result.values())\n",
    "total_matches = sum(item['num_matches'] for item in result.values())\n",
    "print(f'true positive rate: {total_matches/total:.2f}')\n",
    "print(f'falsely identified {total_matches} out of {total}')"
   ],
   "id": "d0b3814b18fa75fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positive rate: 0.00\n",
      "falsely identified 13 out of 13060\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:46:21.250339Z",
     "start_time": "2025-01-21T12:46:21.247998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, value in result.items():\n",
    "    if value['num_matches'] > 0:\n",
    "        print(key, value, sep='\\t')"
   ],
   "id": "4e7da504c77341",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country,county\t{'num_sentences': 100, 'num_matches': 3}\n",
      "form,from\t{'num_sentences': 839, 'num_matches': 1}\n",
      "life,live\t{'num_sentences': 147, 'num_matches': 1}\n",
      "their,there,they\t{'num_sentences': 1421, 'num_matches': 3}\n",
      "theme,them\t{'num_sentences': 246, 'num_matches': 1}\n",
      "two,too,to\t{'num_sentences': 4563, 'num_matches': 1}\n",
      "whole,hole\t{'num_sentences': 33, 'num_matches': 1}\n",
      "you,your\t{'num_sentences': 698, 'num_matches': 2}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:05:17.827058Z",
     "start_time": "2025-01-21T14:05:17.816819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('../experiments/data/report_false_positives.csv', 'a') as f:\n",
    "    print('confusion_set', 'num_matches', 'num_sentences', sep=';', file=f)\n",
    "    for key, value in result.items():\n",
    "        print(key, value['num_matches'], value['num_sentences'], sep=';', file=f)\n",
    "        print(key, value['num_matches'], value['num_sentences'], sep='\\t')"
   ],
   "id": "327a5af8756a2143",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accept,except\t0\t20\n",
      "advise,advice\t0\t21\n",
      "affect,effect\t0\t31\n",
      "begin,being\t0\t213\n",
      "bitch,pitch\t0\t7\n",
      "brakes,breaks\t0\t7\n",
      "burrows,borrows\t0\t0\n",
      "sight,site\t0\t29\n",
      "cords,chords\t0\t0\n",
      "country,county\t3\t100\n",
      "crap,crab\t0\t2\n",
      "dessert,desert\t0\t6\n",
      "ease,easy\t0\t30\n",
      "effects,affects\t0\t23\n",
      "extend,extent\t0\t16\n",
      "feet,feat\t0\t21\n",
      "few,view\t0\t103\n",
      "form,from\t1\t839\n",
      "forth,fourth\t0\t33\n",
      "forums,forms\t0\t3\n",
      "fund,found\t0\t115\n",
      "lead,led\t0\t96\n",
      "life,live\t1\t147\n",
      "loose,lose\t0\t20\n",
      "mad,made\t0\t154\n",
      "or,ore\t0\t413\n",
      "passed,past\t0\t80\n",
      "peace,piece\t0\t28\n",
      "plane,plain\t0\t12\n",
      "principal,principle\t0\t13\n",
      "quite,quiet\t0\t37\n",
      "raise,rise\t0\t32\n",
      "safe,save\t0\t48\n",
      "spit,split\t0\t9\n",
      "than,then\t0\t419\n",
      "their,there,they\t3\t1421\n",
      "theme,them\t1\t246\n",
      "things,thinks\t0\t69\n",
      "trail,trial\t0\t27\n",
      "tree,three\t0\t174\n",
      "two,too,to\t1\t4563\n",
      "weak,week\t0\t121\n",
      "weather,whether\t0\t56\n",
      "weed,wheat\t0\t1\n",
      "where,were\t0\t598\n",
      "which,witch\t0\t424\n",
      "whole,hole\t1\t33\n",
      "with,width\t0\t1383\n",
      "world,word\t0\t119\n",
      "you,your\t2\t698\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
